networks:
  telemetry-net:
    driver: bridge

services:
  prometheus:
    image: artificer-prometheus:latest
    container_name: telemetry-prometheus
    restart: unless-stopped
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=30d
      - --web.console.libraries=/usr/share/prometheus/console_libraries
      - --web.console.templates=/usr/share/prometheus/consoles
    networks:
      - telemetry-net
    volumes:
      - prometheus-data:/prometheus
      - ../prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../prometheus/targets:/etc/prometheus/targets:ro
    ports:
      - "127.0.0.1:9090:9090"
    profiles:
      - central

  grafana:
    image: artificer-grafana:latest
    container_name: telemetry-grafana
    restart: unless-stopped
    ports:
      - "127.0.0.1:3001:3000"
    networks:
      - telemetry-net
    volumes:
      - grafana-data:/var/lib/grafana
      - ../grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_SECURITY_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=${GF_SERVER_ROOT_URL:-http://localhost:3001}
    depends_on:
      - prometheus
    profiles:
      - central

  telemetry-dashboard:
    image: nginx:1.29.4-alpine
    container_name: telemetry-dashboard
    restart: unless-stopped
    pull_policy: if_not_present
    ports:
      - "127.0.0.1:8080:80"
    networks:
      - telemetry-net
    volumes:
      - ../dashboard:/usr/share/nginx/html:ro
      - ../dashboard/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - prometheus
    profiles:
      - central

  node-exporter:
    image: artificer-node-exporter:latest
    container_name: telemetry-node-exporter
    restart: unless-stopped
    pid: host
    command:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/rootfs
      - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
      - --collector.textfile.directory=/var/lib/node_exporter/textfile_collector
    networks:
      - telemetry-net
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - node-exporter-textfile:/var/lib/node_exporter/textfile_collector:ro
    ports:
      # Expose on all interfaces so a central Prometheus can scrape this node over the LAN.
      # If you only want local scraping, change back to "127.0.0.1:9100:9100".
      - "9100:9100"
    profiles:
      - central
      - node

  system-info-metrics:
    image: python:3.11-slim
    container_name: telemetry-system-info-metrics
    restart: unless-stopped
    # Needs host pid+net namespaces to resolve interface IPv4 via ioctl.
    pid: host
    network_mode: host
    command:
      - /bin/sh
      - -c
      - |
        python /opt/system_info_textfile.py --output-dir /var/lib/node_exporter/textfile_collector --proc-root /host/proc --interval-seconds 10
    environment:
      - TELEMETRY_USER=${TELEMETRY_USER}
    volumes:
      - /proc:/host/proc:ro
      - /etc/passwd:/host/etc/passwd:ro
      - node-exporter-textfile:/var/lib/node_exporter/textfile_collector:rw
      - ../system_info_textfile.py:/opt/system_info_textfile.py:ro
    profiles:
      - central

  amd-gpu-metrics:
    image: python:3.11-slim
    container_name: telemetry-amd-gpu-metrics
    restart: unless-stopped
    # Writes AMD GPU metrics into node_exporter textfile collector volume.
    command:
      - /bin/sh
      - -c
      - |
        python /opt/amd_gpu_textfile.py --output-dir /var/lib/node_exporter/textfile_collector --interval-seconds 5
    networks:
      - telemetry-net
    volumes:
      # Read sysfs for AMDGPU metrics
      - /sys:/sys:ro
      # Write into node_exporter textfile collector volume (must be RW here)
      - node-exporter-textfile:/var/lib/node_exporter/textfile_collector:rw
      # Mount the script from the repo
      - ../gpu/amd_gpu_textfile.py:/opt/amd_gpu_textfile.py:ro
    environment:
      # Optional override for a friendly GPU model name shown in the dashboard.
      - TELEMETRY_GPU_NAME=${TELEMETRY_GPU_NAME}
    profiles:
      - amd

  top-process-metrics:
    image: python:3.11-slim
    container_name: telemetry-top-process-metrics
    restart: unless-stopped
    # Writes top-N CPU/memory processes into node_exporter textfile collector volume.
    command:
      - /bin/sh
      - -c
      - |
        python /opt/top_processes_textfile.py --output-dir /var/lib/node_exporter/textfile_collector --proc-root /host/proc --interval-seconds 5
    networks:
      - telemetry-net
    volumes:
      # Read host procfs for per-process stats
      - /proc:/host/proc:ro
      # Write into node_exporter textfile collector volume (must be RW here)
      - node-exporter-textfile:/var/lib/node_exporter/textfile_collector:rw
      # Mount the script from the repo
      - ../processes/top_processes_textfile.py:/opt/top_processes_textfile.py:ro
    profiles:
      - processes

volumes:
  prometheus-data:
  grafana-data:
  node-exporter-textfile:

